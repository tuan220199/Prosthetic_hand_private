{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from data_loader import CustomSignalData, CustomSignalData1\n",
    "from torch.autograd import Variable\n",
    "from encoder import Encoder as E\n",
    "from helpers import set_cmd_cb, rms_formuula, get_data, get_all_data, get_shift_data, get_operators, plot_cfs_mat, roll_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "def getFeatureMatrix(rawDataMatrix, windowLength, windowOverlap):\n",
    "    rms = lambda sig: np.sqrt(np.mean(sig**2))\n",
    "    nChannels,nSamples = rawDataMatrix.shape    \n",
    "    I = int(np.floor(nSamples/(windowLength-windowOverlap)))\n",
    "    featMatrix = np.zeros([nChannels, I])\n",
    "    for channel in range(nChannels):\n",
    "        for i in range (I):\n",
    "            wdwStrtIdx=i*(windowLength-windowOverlap)\n",
    "            sigWin = rawDataMatrix[channel][wdwStrtIdx:(wdwStrtIdx+windowLength-1)] \n",
    "            featMatrix[channel, i] = rms(sigWin)\n",
    "    featMatrixData = np.array(featMatrix)\n",
    "    return featMatrixData\n",
    "\n",
    "class FFNN(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(inputSize, 9, bias=False),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        self.classifer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(9, outputSize, bias=False),\n",
    "            # torch.nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, encoder=None):\n",
    "        if not encoder:\n",
    "            encoder = self.encoder\n",
    "        z = encoder(x)\n",
    "        class_z = self.classifer(z)\n",
    "\n",
    "        return class_z\n",
    "\n",
    "class Operator(nn.Module):\n",
    "    def __init__(self, in_features, n_rotations):\n",
    "        super(Operator, self).__init__()\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          in_features (int): Number of input features which should be equal to xsize.\n",
    "          out_features (out): Number of output features which should be equal to ysize.\n",
    "        \"\"\"\n",
    "        self.in_features = in_features\n",
    "        self.core = torch.nn.Parameter(torch.zeros(3*self.in_features**2)- 0*torch.diag(torch.rand(3*self.in_features**2)/10))\n",
    "        self.core.requires_grad = True\n",
    "        self.n_rotations = n_rotations\n",
    "        \n",
    "    def rotate_batch(self, x, d, out_features):\n",
    "      rotated = torch.empty(x.shape[0], 3*out_features*out_features, device=DEVICE)\n",
    "      phies = [torch.linalg.matrix_power(self.core,i).to(DEVICE) for i in range (0,self.n_rotations+0)]\n",
    "      for i in range (x.shape[0]):\n",
    "        rotated[i] = phies[(d[i]+0)%4].matmul(x[i]) \n",
    "      return rotated\n",
    "\n",
    "    def forward(self, x, d):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, 3, xsize, xsize): Inputs.\n",
    "        \n",
    "        Returns:\n",
    "          y of shape (batch_size, 3*xsize^2): Outputs.\n",
    "        \"\"\"\n",
    "        z = self.rotate_batch(x, d, self.in_features)\n",
    "        return z\n",
    "def get_tensor(arr):\n",
    "    return torch.tensor(arr, device=DEVICE,dtype=torch.float )\n",
    "\n",
    "def rotate_batch(x, d, out_features):\n",
    "    M = torch.diag(torch.ones(8)).roll(-1,1)\n",
    "    used_bases = [torch.linalg.matrix_power(M,i).to(DEVICE) for i in range (8)]\n",
    "    rotated = torch.empty(x.shape, device=DEVICE)\n",
    "    for i in range (x.shape[0]):\n",
    "        rotated[i] = used_bases[d[i]].matmul(x[i]) \n",
    "    return rotated\n",
    "\n",
    "def clf_acc(model, loader, masks = None, encoder = None):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    iter = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels,_,_ in loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            if masks is not None:\n",
    "                inputs = inputs * masks[:inputs.size()[0]]\n",
    "            labels = labels.to(DEVICE)\n",
    "            labels = labels.flatten()\n",
    "            if encoder:\n",
    "                pred = model(inputs, encoder)\n",
    "            else:\n",
    "                pred = model(inputs)\n",
    "            correct += (1-torch.abs(torch.sign(torch.argmax(pred,dim = 1)- labels))).mean().item()\n",
    "            iter += 1\n",
    "    return correct/iter\n",
    "\n",
    "def compute_accuracy(a, b, loader):\n",
    "    a.eval()\n",
    "    b.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    iter = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs1, inputs2, shift1, shift2, labels, _ in loader:\n",
    "            inputs1 = inputs1.to(DEVICE)\n",
    "            inputs2 = inputs2.to(DEVICE)\n",
    "            shift1 = -shift1.int().flatten().to(DEVICE)\n",
    "            shift2 = -shift2.int().flatten().to(DEVICE)\n",
    "            labels = labels.flatten().to(DEVICE)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            y1 = a(inputs1)\n",
    "            y_tr_est1 = rotate_batch(y1,shift1,6)\n",
    "            y_tr1 = b(y_tr_est1)\n",
    "\n",
    "            y2 = a(inputs2)\n",
    "            y_tr_est2 = rotate_batch(y2,shift1,6)\n",
    "            y_tr2 = b(y_tr_est2)\n",
    "\n",
    "            correct += (1-torch.abs(torch.sign(torch.argmax(y_tr1,dim = 1)- labels))).mean().item() + \\\n",
    "                    (1-torch.abs(torch.sign(torch.argmax(y_tr2,dim = 1)- labels))).mean().item()\n",
    "            iter += 1\n",
    "    return correct * 0.5 / iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = '22'\n",
    "No_shift = '1'\n",
    "\n",
    "Fs = 1000\n",
    "windowLength = int(np.floor(0.1*Fs))  #160ms\n",
    "windowOverlap =  int(np.floor(50/100 * windowLength))\n",
    "\n",
    "# X_train = np.zeros([0,8])\n",
    "# y_train= np.zeros([0])\n",
    "X_test = np.zeros([0,8])\n",
    "y_test = np.zeros([0])\n",
    "\n",
    "for shift in range(0,int(No_shift)): \n",
    "    for files in sorted(os.listdir(f'Subject_{subject}/Shift_5/')):\n",
    "        _, class_,_, rep_ = files.split('_')\n",
    "        if int(class_) in [1,2,3,4,5,6,7,8,9]:\n",
    "            df = pd.read_csv(f'Subject_{subject}/Shift_5/{files}',skiprows=0,sep=' ',header=None)\n",
    "            data_arr = np.stack([np.array(df.T[i::8]).T.flatten().astype('float32') for i in range (8)])\n",
    "            data_arr -= 121\n",
    "            data_arr /= 255.0\n",
    "            feaData = getFeatureMatrix(data_arr, windowLength, windowOverlap)\n",
    "            \n",
    "            if not class_.startswith('9'):\n",
    "                rms_feature = feaData.sum(0)\n",
    "                baseline = 2*rms_feature[-50:].mean()\n",
    "                start_ = np.argmax(rms_feature[::1]>baseline)\n",
    "                end_  = -np.argmax(rms_feature[::-1]>baseline)\n",
    "                feaData = feaData.T[start_:end_]\n",
    "            else:\n",
    "                feaData = feaData.T\n",
    "\n",
    "            # if rep_.startswith('2'):\n",
    "            #     X_test = np.concatenate([X_test,feaData])\n",
    "            #     y_test = np.concatenate([y_test,np.ones_like(feaData)[:,0]*int(class_)-1])\n",
    "            \n",
    "            X_test = np.concatenate([X_test,feaData])\n",
    "            y_test= np.concatenate([y_test,np.ones_like(feaData)[:,0]*int(class_)-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01358471 0.01684657 0.0059903  ... 0.01526977 0.03508222 0.05078959]\n",
      " [0.01459355 0.0197342  0.00832357 ... 0.02019328 0.04748765 0.05708802]\n",
      " [0.01294052 0.02060827 0.00856275 ... 0.01890604 0.04923975 0.064333  ]\n",
      " ...\n",
      " [0.00506272 0.00176261 0.00294942 ... 0.0031034  0.00197066 0.00336747]\n",
      " [0.00551785 0.00193085 0.00312833 ... 0.00294942 0.00184865 0.00339046]\n",
      " [0.00533391 0.00175378 0.00313112 ... 0.00306911 0.00186016 0.00336776]]\n",
      "(4689, 8)\n",
      "[0. 0. 0. ... 8. 8. 8.]\n",
      "(4689,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "print(X_test.shape)\n",
    "print(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD LEARNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logRegres  = load('LogisticRegression1.joblib')\n",
    "\n",
    "DEVICE = torch.device(\"cpu\") # operations is in CPU or GPU.\n",
    "M = torch.diag(torch.ones(8)).roll(-1,1) # Create a diagnoise matrix then shift it to the right\n",
    "used_bases = [torch.linalg.matrix_power(M,i).to(DEVICE) for i in range (8)] #\n",
    "\n",
    "N_points = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST ACCURACY OF LOGISTIC rEGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3529537214757944, 0.3508210705907443, 0.4130944764342077, 0.3702281936447004, 0.40840264448709745, 0.5397739390061846, 0.4049904030710173, 0.32075069311153764]\n",
      "0.40840264448709745\n"
     ]
    }
   ],
   "source": [
    "accuracies_LosReg_shift = []\n",
    "for i in range (-4, 4):\n",
    "    X_test_shift = roll_data(X_test, i)\n",
    "    accuracies_LosReg_shift.append(logRegres.score(X_test_shift,y_test)) \n",
    "\n",
    "accuracies_LosReg = logRegres.score(X_test, y_test)\n",
    "print(accuracies_LosReg_shift)\n",
    "print(accuracies_LosReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST ACCURACY OF FEED FORWARD NEURAL NETWORK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    " # This model is without opeartor. It is similiarily to the classifier model but do not have encoder\n",
    "modelWOoperator = FFNN(8,9)\n",
    "modelWOoperator.load_state_dict(torch.load(\"modelwoOperator.pt\")) # loaded from the file: parameters learned during training.\n",
    "modelWOoperator.eval() # evaluation mode ensures consistent behavior during inference.\n",
    "\n",
    "\n",
    "accuracies_ffnn = []\n",
    "for i in range (-4, 4):\n",
    "    X_test_shift = roll_data(X_test, i)\n",
    "    test_shift_dataset = CustomSignalData(get_tensor(X_test_shift), get_tensor(y_test))\n",
    "    testshiftloader = torch.utils.data.DataLoader(test_shift_dataset, batch_size=24, shuffle=True)\n",
    "    accuracies_ffnn.append(clf_acc(modelWOoperator, testshiftloader, encoder = None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.671768707888467, 0.6033163275949809, 0.5858134934488608, 0.6535572584490387, 0.5742630408126481, 0.6167091845857854, 0.6476757368262933, 0.575609411664155]\n"
     ]
    }
   ],
   "source": [
    "print(accuracies_ffnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5742630395962267\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CustomSignalData(get_tensor(X_test), get_tensor(y_test))\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=24, shuffle=True)\n",
    "accuracies_ffnn_single = clf_acc(modelWOoperator, testloader, encoder = None)\n",
    "print(accuracies_ffnn_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST ACCURACY OF SELF-SUPERVISED LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1943e-02,  7.0172e-03,  1.8266e-02,  ...,  1.5343e-02,\n",
      "          2.2784e-03,  3.2136e-02],\n",
      "        [ 1.1721e-01,  5.5396e-02,  1.8309e-01,  ...,  6.2217e-02,\n",
      "          3.4511e-02,  4.1451e-02],\n",
      "        [ 8.6316e-02,  3.0073e-02,  1.6398e-01,  ...,  5.3353e-02,\n",
      "         -9.6507e-03,  1.6960e-01],\n",
      "        ...,\n",
      "        [ 1.7151e-02,  3.5203e-02,  3.3019e-04,  ...,  5.2602e-02,\n",
      "          7.1660e-02,  2.5194e-02],\n",
      "        [ 1.4617e-01,  2.4301e-01,  1.2075e-01,  ...,  4.0121e-02,\n",
      "         -2.9864e-02,  2.1188e-01],\n",
      "        [-5.6227e-02,  3.3742e-01,  3.7218e-01,  ...,  9.2131e-02,\n",
      "         -7.3398e-02,  2.3686e-01]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m)):\n\u001b[1;32m     25\u001b[0m         x_rotated \u001b[38;5;241m=\u001b[39m used_bases[d]\u001b[38;5;241m.\u001b[39mmatmul(y_)\u001b[38;5;241m.\u001b[39mrepeat(N_points,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m         distances[d] \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_rotated\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mrecovered_points_\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopk\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlargest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     y_tr_rotated[j] \u001b[38;5;241m=\u001b[39m distances\u001b[38;5;241m.\u001b[39margmin()\n\u001b[1;32m     28\u001b[0m y_tr_est1 \u001b[38;5;241m=\u001b[39m rotate_batch(y1, y_tr_rotated\u001b[38;5;241m.\u001b[39mint(),\u001b[38;5;241m6\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = FFNN(8,9) # This indicates that the neural network expects input data with 8 features and will produce output predictions across 9 classes.\n",
    "encoder = E(8,8)\n",
    "encoder.load_state_dict(torch.load(\"encoder.pt\")) # contains the learned parameters (weights and biases) of the encoder model\n",
    "recovered_points_= torch.load(\"reference_points.pt\") # These points represent reference points for inference or evaluation in the model\n",
    "print(recovered_points_)\n",
    "classifier.load_state_dict(torch.load(\"classifier.pt\")) # contains the weights and biases learned during training.\n",
    "classifier.eval() # sets the model to evaluation mode.\n",
    "encoder.eval() # sets the model to evaluation mode.\n",
    "# with torch.no_grad():\n",
    "#     encoder.eval()\n",
    "#     N_points = 1000\n",
    "#     rand_idx = np.random.choice(all_X_test.shape[0], N_points)\n",
    "#     y_tr = encoder(get_tensor(all_X_test[rand_idx]))\n",
    "#     recovered_points_ = rotate_batch(y_tr,-all_shift_test[rand_idx].flatten(), 6)\n",
    "#     del y_tr\n",
    "\n",
    "accuracies_inferred_operator = []\n",
    "for i in range (-4, 4):\n",
    "    X_test_shift = roll_data(X_test, i)\n",
    "    y1 = encoder(get_tensor(X_test_shift))\n",
    "    y_tr_rotated = torch.zeros(X_test_shift.shape[0])\n",
    "    for j, y_ in enumerate(y1):\n",
    "        distances = np.zeros(8)\n",
    "        for d in (range(-4,4)):\n",
    "            x_rotated = used_bases[d].matmul(y_).repeat(N_points,1)\n",
    "            distances[d] = ((x_rotated-recovered_points_)**2).mean(1).topk(2, largest=False)[0].mean()\n",
    "        y_tr_rotated[j] = distances.argmin()\n",
    "    y_tr_est1 = rotate_batch(y1, y_tr_rotated.int(),6)\n",
    "    y_tr1 = classifier(y_tr_est1).argmax(1)\n",
    "    # print(y_tr1- get_tensor(y_test).flatten())\n",
    "    accuracies_inferred_operator.append((1-torch.abs(torch.sign(y_tr1- get_tensor(y_test).flatten()))).mean())\n",
    "\n",
    "print(accuracies_inferred_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5967)\n"
     ]
    }
   ],
   "source": [
    "# No need for shifting or rotating, directly use X_test\n",
    "y1 = encoder(get_tensor(X_test))\n",
    "\n",
    "# Calculate the rotated indices\n",
    "y_tr_rotated = torch.zeros(X_test.shape[0])\n",
    "for j, y_ in enumerate(y1):\n",
    "    distances = np.zeros(8)\n",
    "    for d in range(-4, 4):\n",
    "        x_rotated = used_bases[d].matmul(y_).repeat(N_points, 1)\n",
    "        distances[d] = ((x_rotated - recovered_points_)**2).mean(1).topk(2, largest=False)[0].mean()\n",
    "    y_tr_rotated[j] = distances.argmin()\n",
    "\n",
    "# Estimate rotated representations\n",
    "y_tr_est1 = rotate_batch(y1, y_tr_rotated.int(), 6)\n",
    "\n",
    "# Classify the rotated representations\n",
    "y_tr1 = classifier(y_tr_est1).argmax(1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (1 - torch.abs(torch.sign(y_tr1 - get_tensor(y_test).flatten()))).mean()\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1944"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27*9*8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
